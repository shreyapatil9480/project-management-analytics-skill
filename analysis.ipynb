{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf79646",
   "metadata": {},
   "source": [
    "\n",
    "# Project Management Analytics\n",
    "\n",
    "This notebook demonstrates a comprehensive data analysis workflow on a synthetic project management dataset. It covers data loading, cleaning, exploratory data analysis (EDA), and predictive modeling. The goal is to showcase skills relevant to roles like Business Analyst, Program Manager, and Data Analyst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1714d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Load dataset\n",
    "file_path = 'synthetic_project_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display first few rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07528468",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data types and basic info\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e159ff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for missing values\n",
    "missing = df.isnull().sum()\n",
    "missing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8819e28",
   "metadata": {},
   "source": [
    "\n",
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's explore the dataset through summary statistics and visualizations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Descriptive statistics\n",
    "stats = df.describe(include='all')\n",
    "stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a182dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Histograms for numeric variables\n",
    "numeric_cols = ['Team_Size', 'Duration_Months', 'Budget', 'Expenditure', 'Risk_Rating', 'Completion_Percent']\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(numeric_cols, 1):\n",
    "    plt.subplot(2, 3, i)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0dfe51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bar charts for categorical variables\n",
    "categorical_cols = ['Project_Priority', 'Phase', 'On_Time', 'Success']\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(categorical_cols, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.countplot(x=df[col], palette='viridis')\n",
    "    plt.title(f'Count of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Correlation matrix for numeric variables\n",
    "corr_matrix = df[['Team_Size', 'Duration_Months', 'Budget', 'Expenditure', 'Risk_Rating', 'Completion_Percent', 'On_Time', 'Success']].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc807e50",
   "metadata": {},
   "source": [
    "\n",
    "## Predictive Modeling\n",
    "\n",
    "We will build classification models to predict whether a project will be successful based on features such as budget, duration, risk rating, and completion percentage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb38f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare features and target\n",
    "X = df[['Team_Size', 'Duration_Months', 'Budget', 'Expenditure', 'Risk_Rating', 'Completion_Percent', 'On_Time']]\n",
    "y = df['Success']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Feature scaling is not strictly necessary for tree-based models, but beneficial for logistic regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d8ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluation metrics\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "precision_lr = precision_score(y_test, y_pred_lr)\n",
    "recall_lr = recall_score(y_test, y_pred_lr)\n",
    "roc_auc_lr = roc_auc_score(y_test, log_reg.predict_proba(X_test_scaled)[:,1])\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {acc_lr:.2f}\")\n",
    "print(f\"Precision: {precision_lr:.2f}\")\n",
    "print(f\"Recall: {recall_lr:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc_lr:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eef42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Forest model\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluation metrics for random forest\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(y_test, rf_clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "print(f\"Random Forest Accuracy: {acc_rf:.2f}\")\n",
    "print(f\"Precision: {precision_rf:.2f}\")\n",
    "print(f\"Recall: {recall_rf:.2f}\")\n",
    "print(f\"ROC AUC: {roc_auc_rf:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007dab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot ROC curves for both models\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test, log_reg.predict_proba(X_test_scaled)[:,1])\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, rf_clf.predict_proba(X_test)[:,1])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {roc_auc_lr:.2f}')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {roc_auc_rf:.2f}')\n",
    "plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
